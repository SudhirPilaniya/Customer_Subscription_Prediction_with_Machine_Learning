# -*- coding: utf-8 -*-
"""ProjectIITKoct.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qUsVw9VnCFnS7PuePJhbAdHAR1EyuE0k
"""

!wget "https://archive.ics.uci.edu/static/public/222/bank+marketing.zip"

!unzip "bank+marketing.zip"
!unzip "bank-additional.zip"

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.preprocessing import LabelEncoder

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

data = pd.DataFrame(pd.read_csv("bank-additional/bank-additional-full.csv",sep=';'))

data.head()

data = data.loc[data['job'] != 'unknown']
data = data.loc[data['loan'] != 'unknown']
data = data.loc[data['housing'] != 'unknown']
data = data.loc[data['marital'] != 'unknown']
data = data.loc[data['education'] != 'unknown']
data = data.loc[data['default'] != 'unknown']

data.info()

Q1=data.quantile(0.25)
Q3=data.quantile(0.75)
IQR = Q3-Q1
print(IQR)

plt.figure(figsize=(12,8))
plt.subplot(3,4,1)
data['age'].plot(kind='hist',bins=20)
plt.subplot(3,4,2)
data['duration'].plot(kind='hist',bins=20)
plt.subplot(3,4,3)
data['campaign'].plot(kind='hist',bins=20)
plt.subplot(3,4,4)
data['pdays'].plot(kind='hist',bins=20)
plt.subplot(3,4,5)
data['previous'].plot(kind='hist',bins=20)
plt.subplot(3,4,6)
data['emp.var.rate'].plot(kind='hist',bins=20)
plt.subplot(3,4,7)
data['cons.price.idx'].plot(kind='hist',bins=20)
plt.subplot(3,4,8)
data['nr.employed'].plot(kind='hist',bins=20)
plt.subplot(3,4,9)
data['cons.conf.idx'].plot(kind='hist',bins=20)
plt.subplot(3,4,10)
data['euribor3m'].plot(kind='hist',bins=20)

#drop the values that are not in the quartile range as outliers column wise
columns = ['job','education', 'marital','default','housing','contact','loan','month','day_of_week','potcome']
for column in data.columns:
  if column not in column:
    data.drop(data[(data[column] < (Q1.column - 1.5*IQR.column)) | (data[column] > (Q3.column + 1.5 * IQR.column))].index, inplace=True)

data = data.drop('default',axis=1)

data.info()

label_encoder = LabelEncoder()

data['marital'] = label_encoder.fit_transform(data['marital'])
data['contact'] = label_encoder.fit_transform(data['contact'])
data['housing'] = label_encoder.fit_transform(data['housing'])
data['education'] = label_encoder.fit_transform(data['education'])
data['loan'] = label_encoder.fit_transform(data['loan'])
data['day_of_week'] = label_encoder.fit_transform(data['day_of_week'])
data['job'] = label_encoder.fit_transform(data['job'])
data['month'] = label_encoder.fit_transform(data['month'])
data['y'] = label_encoder.fit_transform(data['y'])
data['poutcome'] = label_encoder.fit_transform(data['poutcome'])

data.head()

sns.histplot(data['age'])

data.corr()

data.corr()['y'][:-1]

plt.figure(figsize=(20,20))
sns.heatmap(data.corr(),annot=True, cmap='coolwarm')

#data split
from sklearn.model_selection import train_test_split
X=data.drop('y', axis = 1)
y = data['y']
X_train ,X_test, y_train , y_test = train_test_split(X,y,test_size=0.25,random_state=42)

from sklearn.linear_model import LogisticRegression
logistic_regression = LogisticRegression()
logistic_regression.fit(X_train, y_train)

#prediction on test set
y_pred = logistic_regression.predict(X_test)
#model evaluation using accuracy, f-1 score , precision and recall
from sklearn.metrics import accuracy_score , f1_score , precision_score,recall_score
accuracy = accuracy_score(y_test , y_pred)
f1 = f1_score(y_test,y_pred)
precision=precision_score(y_test,y_pred)
recall = recall_score(y_test, y_pred)

print("Accuracy:", accuracy)
print("F1 Score:", f1)
print("precision:", precision)
print("Recall:", recall)

#using random forest method
from sklearn.ensemble import RandomForestClassifier
random_forest = RandomForestClassifier()
random_forest.fit(X_train, y_train)
#Prediction on test set
y_pred_rf = random_forest.predict(X_test)

# from sklearn.metrics import accuracy_score,f1_score, precision_score
accuracy_random_forest=accuracy_score(y_test,y_pred_rf)
f1_random_forest = f1_score(y_test,y_pred_rf)
precision_random_forest = precision_score(y_test,y_pred_rf)
recall_random_forest=recall_score(y_test,y_pred_rf)

print("values according to random forest method")
print("Accuracy:", accuracy_random_forest)
print("F1 Score:", f1_random_forest)
print("precision:", precision_random_forest)
print("Recall:", recall_random_forest)

#using decision tree algorithm
from sklearn.tree import DecisionTreeClassifier
dTree = DecisionTreeClassifier()
dTree.fit(X_train, y_train)
#prediction on test set
y_pred_dt = dTree.predict(X_test)

accuracy_dTree = accuracy_score(y_test,y_pred_dt)
f1_dTree = f1_score(y_test, y_pred_dt)
precision_dTree = precision_score(y_test, y_pred_dt)
recall_dTree = recall_score(y_test,y_pred_dt)

print("values according to decision tree")
print("Accuracy:", accuracy_dTree)
print("F1 Score:", f1_dTree)
print("precision:", precision_dTree)
print("Recall:", recall_dTree)

